# -*- coding: utf-8 -*-
"""FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qLr-8f7j0_2ugYJKfr4tp9EVYDQikMnd

# CI Final Project Alireza Rashidi

## Loading Dataset:
"""

from google.colab import drive
drive.mount('/content/drive')

!cp /content/drive/MyDrive/Datasets/train2.zip /content/sample_data

!mkdir /content/Final_Project
!unzip /content/sample_data/train2.zip -d /content/Final_Project

import pandas as pd
import numpy as np
from tensorflow import keras
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.layers import SpatialDropout1D
from tensorflow.keras.layers import Embedding
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import svm
from sklearn.metrics import classification_report, confusion_matrix

df= pd.read_csv('/content/Final_Project/train.csv', sep=',')
df.head(10)

"""## Data Preprocessing(For RNN model):"""

print(df.shape)
# df = df.dropna()
# print(df.shape)

data = df[['title','recommend']]
data.head(10)

data = data.dropna()
print(df.isnull().values.any())
print(data.shape)

# mapping labels to integer values
sentiment_label = data.recommend.factorize()
sentiment_label

# tokenize words in our dataset
pad_size = 210

data_text = data.title.values
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(data_text)

vocab_size = len(tokenizer.word_index) + 1
encoded_docs = tokenizer.texts_to_sequences(data_text)

#The sentences have different number of words, therefore, the length of the sequence of numbers will be different. Our model requires inputs to have equal lengths, so we will have to pad the sequence to have the chosen length of inputs
padded_sequence = pad_sequences(encoded_docs, maxlen=pad_size)

print('word mappings: ', tokenizer.word_index)
print('\npadded words: \n', padded_sequence)

idx = 0
print('\nactual text: ', data_text[idx])
print('encodded text: ', encoded_docs[idx])

"""### train_test_validation split:"""

X_train, X_test, Y_train, Y_test = train_test_split(padded_sequence, sentiment_label[0], test_size = 0.20, random_state = 42)
print("train set: ", X_train.shape, Y_train.shape)
print("test set: ", X_test.shape, Y_test.shape)

validation_len = int(X_test.shape[0] / 2)
X_val = X_test[:validation_len]
Y_val = Y_test[:validation_len]

X_test = X_test[validation_len:]
Y_test = Y_test[validation_len:]

print("validation set: ", X_val.shape, Y_val.shape)
print("test set: ", X_test.shape, Y_test.shape)

print('\n', X_val[:5])
print(Y_val[:5], '\n')
print(X_test[:5])
print(Y_test[:5])

"""## Creating RNN Model:"""

embedding_vector_length = 32
batch_size = 64

model = Sequential()
model.add(Embedding(vocab_size, embedding_vector_length, input_length=pad_size))
model.add(SpatialDropout1D(0.25))
model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))
model.add(Dropout(0.2))

model.add(Dense(1, activation='sigmoid'))   # we have binary classification
model.compile(loss='binary_crossentropy',optimizer='adam', 
                           metrics=['accuracy'])
print(model.summary())

history = model.fit(X_train, Y_train, epochs=5, batch_size=batch_size, validation_data=(X_val, Y_val))

def learningCurve_plot(hs3, epochs3, loss, model_name):    # ploting learining curve plot for created model.
    if loss:
        plt.plot(np.arange(1, epochs3+1), hs3.history["loss"], label="train_loss")
        plt.plot(np.arange(1, epochs3+1), hs3.history["val_loss"], label="val_loss")
        plt.title(" ".join(["Learning curve loss", model_name]))
        plt.xlabel("Epoch #")
        plt.ylabel("Loss")
        plt.legend()
        plt.show()
    else:   
        plt.plot(np.arange(1, epochs3+1), hs3.history["accuracy"], label="train_acc")
        plt.plot(np.arange(1, epochs3+1), hs3.history["val_accuracy"], label="val_acc")
        plt.title(" ".join(["Learning curve accuracy", model_name]))
        plt.xlabel("Epoch #")
        plt.ylabel("Accuracy")
        plt.legend()
        plt.show()

learningCurve_plot(history, 5, True, "LSTM loss")

learningCurve_plot(history, 5, False, "LSTM acc")

"""## Prediction using test set:"""

scores = model.evaluate(X_test, Y_test, verbose=1)
print('Test accuracy:', scores[1])
print('Test loss:', scores[0])

"""### here we test some text input for verifying our models functionalty:"""

# using some test word for prediction...

test_word = 'خوب هست'
tw = tokenizer.texts_to_sequences([test_word])
tw = pad_sequences(tw, maxlen=pad_size)

prediction = int(model.predict(tw).round().item())
print("predicted result is: ", sentiment_label[1][prediction])

"""## Using SVM model on the title column:
in this part i used converted title data for training svm model.
"""

svclassifier = svm.SVC(kernel='rbf')
svclassifier.fit(X_train, Y_train)

y_pred_val = svclassifier.predict(X_val)

val_cf = confusion_matrix(Y_val, y_pred_val)
print(val_cf)
print(classification_report(Y_val, y_pred_val))

sns.heatmap(val_cf, annot=True)

y_pred_test = svclassifier.predict(X_test)
test_cf = confusion_matrix(Y_test, y_pred_test)
print(test_cf)
print(classification_report(Y_test, y_pred_test))

sns.heatmap(test_cf, annot=True)

test_word = 'بد'
tw = tokenizer.texts_to_sequences([test_word])
tw = pad_sequences(tw, maxlen=pad_size)

prediction = svclassifier.predict(tw)[0]
print("predicted result is: ", sentiment_label[1][prediction])

"""from the above results we can see that our SVM model on text data, is not as good as RNN model.

## Using SVM model(for likes/dislikes column):
this model's preprocessing is bit much different from RNN model
"""

data = df[['likes','dislikes']]
labels = df['recommend']
data.head(10)

print(data.isnull().values.any())
print(labels.isnull().values.any())
features = data.to_numpy()
labels = labels.factorize()
print('\nselected features shape: ', features.shape)
print('\nencoded labels for problem: ', labels)

"""## Some data visualizations based on labels and likes/dislikes:"""

plt.scatter(range(1, features.shape[0]+1), features[:,0], label='likes')
plt.scatter(range(1, features.shape[0]+1), features[:,1], label='dislikes')
plt.xlabel('product #')
plt.ylabel('# of likes/dislikes')
plt.legend()

s = plt.scatter(range(1, features.shape[0]+1), features[:,0], c=labels[0], cmap="jet")
plt.legend(handles=s.legend_elements()[0],
           labels=['0:recommended', '1:not_recommended'],
           title="labels")

plt.title('plot according to class labels for each product(likes)')
plt.xlabel('product #')
plt.ylabel('# of likes')

s = plt.scatter(range(1, features.shape[0]+1), features[:,1], c=labels[0], cmap="jet")
plt.legend(handles=s.legend_elements()[0],
           labels=['0:recommended', '1:not_recommended'],
           title="labels")

plt.title('plot according to class labels for each product(dislikes)')
plt.xlabel('product #')
plt.ylabel('# of dislikes')

X_train, X_test, Y_train, Y_test = train_test_split(features, labels[0], test_size = 0.20, random_state = 42)
print("train set: ", X_train.shape, Y_train.shape)
print("test set: ", X_test.shape, Y_test.shape)

validation_len = int(X_test.shape[0] / 2)
X_val = X_test[:validation_len]
Y_val = Y_test[:validation_len]

X_test = X_test[validation_len:]
Y_test = Y_test[validation_len:]

print("validation set: ", X_val.shape, Y_val.shape)
print("test set: ", X_test.shape, Y_test.shape)

print('\n', X_val[:5])
print(Y_val[:5], '\n')
print(X_test[:5])
print(Y_test[:5])

"""## creating model and fiting it on the data:"""

svclassifier = svm.SVC(kernel='rbf')
svclassifier.fit(X_train, Y_train)

"""## SVM Model evaluation:"""

y_pred_val = svclassifier.predict(X_val)

val_cf = confusion_matrix(Y_val, y_pred_val)
print(val_cf)
print(classification_report(Y_val, y_pred_val))

sns.heatmap(val_cf, annot=True)

y_pred_test = svclassifier.predict(X_test)
test_cf = confusion_matrix(Y_test, y_pred_test)
print(test_cf)
print(classification_report(Y_test, y_pred_test))

sns.heatmap(test_cf, annot=True)